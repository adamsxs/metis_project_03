{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial EDA and Modelling for Scania Truck Data Classification Problem\n",
    "Scania is looking to determine during a checkup whether the Air Pressure System (APS), the system that controls the trucks' ability to brake (among other things), is in need of replacement. They have provided a training set of 60,000 examples with over 170 features. Models are scored using a custom cost function that heavily penalizes Type II classification errors (false negatives) on a test set of 16,000 examples.\n",
    "\n",
    "I only had the training set from the [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks) available for most of the project, so all references in this notebook to the *test set* refer to a *holdout set from the training data*. I later found the [full dataset hosted on Kaggle](https://www.kaggle.com/uciml/aps-failure-at-scania-trucks-data-set). It includes the original data, which I use below, as well as the test set used in later notebooks and a processed training and test sets that have been standardized, scrubbed, and re-formatted by Kaggle user [ahk3](https://www.kaggle.com/ahkahk). I will be taking a look at other users' strategies after I've gotten my own implementation and score finished.\n",
    "\n",
    "There are no label errors in the test and training sets. However, nearly every row is missing some kind of measurement. It will be necessary to impute the data, find a smart way of dropping NaN's, and learn from trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Custom Modules\n",
    "import data_cleaning as dc\n",
    "from custom_metrics import scania_score\n",
    "from model_testing import cross_val_models\n",
    "\n",
    "# Data Containers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing: standardizing, undersampling, and oversampling, gridsearch\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,\\\n",
    "cross_val_score, StratifiedKFold, StratifiedShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFECV\n",
    "import imblearn\n",
    "\n",
    "#Pipeline Experimentation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Models: dummy, kNN, logistic regression, Naive Bayes, SVM\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Model evaluation metrics\n",
    "# ROC curve\n",
    "# Proprietary cost function\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "auc, log_loss, confusion_matrix, f1_score, make_scorer, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "The following blocks read in the data and do exploratory work on the data. The results from this have been condensed in the `ready_aps_data()` function within `data_cleaning.py`, but I've left the blocks here intact for illustrative purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'aps-failure-at-scania-trucks-data-set/'\n",
    "file = 'aps_failure_training_set.csv'\n",
    "aps = pd.read_csv(folder+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 171 entries, class to eg_000\n",
      "dtypes: int64(1), object(170)\n",
      "memory usage: 78.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Nearly all data enters the dataframe as a string object.\n",
    "aps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label values: ['neg' 'pos']\n",
      "Negative class observations: 59000\n",
      "Positive class observations: 1000\n"
     ]
    }
   ],
   "source": [
    "# Checking for weird labels\n",
    "print('Label values:', aps['class'].unique())\n",
    "mask = aps['class']=='neg'\n",
    "print('Negative class observations:',aps[mask]['class'].shape[0] )\n",
    "print('Positive class observations:', aps[~mask]['class'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe for EDA\n",
    "# For each column in dataframe, make that column numeric\n",
    "\n",
    "X = aps.iloc[:,1:].copy(deep=True)\n",
    "y = aps['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns are majority `NaN` values, to the extent that I don't think I'll gain any information from using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "na    771\n",
       "0     155\n",
       "2      38\n",
       "4      17\n",
       "6       9\n",
       "8       5\n",
       "48      1\n",
       "10      1\n",
       "14      1\n",
       "36      1\n",
       "12      1\n",
       "Name: ab_000, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of missing values, looking at the positive class only\n",
    "X[~mask]['ab_000'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-conversion y\n",
      "object\n",
      "neg    59000\n",
      "pos     1000\n",
      "Name: class, dtype: int64\n",
      "Post-conversion y\n",
      "int64\n",
      "0    59000\n",
      "1     1000\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert target variable to numeric\n",
    "\n",
    "print('Pre-conversion y', y.dtype, y.value_counts(), sep = '\\n')\n",
    "y = pd.Series([0 if lbl == 'neg' else 1 for lbl in y], name = 'class')\n",
    "print('Post-conversion y', y.dtype, y.value_counts(), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all of the features have been imported as objects. This commonly happens in Pandas where at least any one value in the column is string-like, in this case 'na'. Items in a series must use the same object type, so to smooth the conversion to numeric I'm going change 'na' to 'nan'.  \n",
    "\n",
    "In practice, this could be avoided if the software generating the data used 'nan' instead of 'na'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 170 entries, aa_000 to eg_000\n",
      "dtypes: int64(1), object(169)\n",
      "memory usage: 77.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 170 entries, aa_000 to eg_000\n",
      "dtypes: float64(169), int64(1)\n",
      "memory usage: 77.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert columns to numeric by first replacing 'na' with NaN for smoother conversion.\n",
    "print(X.info())\n",
    "\n",
    "X.replace('na', np.nan, inplace=True)\n",
    "for column in X.columns:\n",
    "    X[column]= pd.to_numeric(X[column], errors = 'raise')\n",
    "    \n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NaN:\n",
    "Current options:\n",
    "* Drop columns with mostly nan, then drop any row with nan. How many observations do you lose?  \n",
    "* Experiment with [sklearn imputers](http://scikit-learn.org/stable/modules/impute.html)\n",
    "* Use a more sophisticated \n",
    "* Look at feature value distributions to determine which imputation methods (impute mean vs nearest neighbors vs mode, etc) are appropriate for which features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block below goes through the first process. Results are expalined afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns above threshold: 28\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54143 entries, 0 to 59999\n",
      "Columns: 142 entries, aa_000 to eg_000\n",
      "dtypes: float64(141), int64(1)\n",
      "memory usage: 59.1 MB\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Dropping idea: Remove columns w/ NaN percent above a threshold, then drop all corresponding rows\n",
    "nan_cols = dc.get_nan_frac_cols(X, 0.15, graph=True)\n",
    "print('Columns above threshold:',len(nan_cols))\n",
    "\n",
    "X_no_nan = X.drop(nan_cols, axis=1).dropna()\n",
    "X_no_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab_000', 'ad_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'cf_000', 'cg_000', 'ch_000', 'cl_000', 'cm_000', 'co_000', 'cr_000', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'ec_00', 'ed_000']\n"
     ]
    }
   ],
   "source": [
    "# Display columns to drop\n",
    "print(nan_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the effect\n",
    "dc.get_nan_frac_cols(X_no_nan, 0.001, graph=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total remaining observations: 54143\n",
      "Number of negative class: 53738\n",
      "Number of positive class: 405\n"
     ]
    }
   ],
   "source": [
    "# Check that we still have a good amount of negative and positive classes\n",
    "y_no_nan = y[X_no_nan.index].reset_index(drop=True)\n",
    "X_no_nan = X_no_nan.reset_index(drop=True)\n",
    "print('Total remaining observations:',y_no_nan.shape[0])\n",
    "print('Number of negative class:', np.sum(y_no_nan==0))\n",
    "print('Number of positive class:', y_no_nan[y_no_nan==1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping high columns with a high percentage of `NaN` values, then culling the observations with any `NaN` value still leaves 54,143 observations, down from 60,000. We also retained 142 of the 170 featurs. However, of the original 1000 positive examples, only 405 remain. The negative class still has 53,738 observations.  \n",
    "\n",
    "Percent loss, by class, when indiscriminantly dropping NaN values:\n",
    "* Positive class: 59.5%\n",
    "* Negative class:  0.7%  \n",
    "\n",
    "Takeaways:  \n",
    "1) I still have enough examples to train on if necessary.  \n",
    "2) Since the lack of measurements disproportionately affects one class, it could be that the number of missing values is correlated with the class type, and thus should become a feature.  \n",
    "3) Look at imputing the data instead of running a `pandas.DataFrame.dropna()` after removing high-NaN columns.\n",
    "\n",
    "**The above takeaways have been accounted for in the `data_cleaning.ready_aps_data` method. While features (columns) missing most measurements are still dropped, the remaining values are imputed. This retains all of the training set examples, doubles the amount of positive class examples, and increases model performance.**  \n",
    "\n",
    "I also believe it's the approach that conforms better with what would be needed in practice when some measurements are unavailable in the shop and the mechanics still need to make a decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding database to SQL\n",
    "\n",
    "Part of the requirement for this project is to get the data into a SQL database on our AWS server. This would be much more useful if my data was distributed across several tables in a RDMS. I've created a command that iterates through the table columns and creates a string in Postgres SQL syntax that lets me copy/paste the output into a SQL command to create a table.\n",
    "\n",
    "I don't think it's efficient or safe (teasing out misspellings and the like) to manually type out the table creation command for 170 columns with their respective types. The whole point of relational databases is to partition out information in different tables and to then select only what you need, and this dataset doesn't seem like a good fit with that principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE aps_data (aa_000 FLOAT, ab_000 FLOAT, ac_000 FLOAT, ad_000 FLOAT, ae_000 FLOAT, af_000 FLOAT, ag_000 FLOAT, ag_001 FLOAT, ag_002 FLOAT, ag_003 FLOAT);\n"
     ]
    }
   ],
   "source": [
    "# 10 column demo. Remove indexing for full table.\n",
    "table_creation = tuple(column + ' FLOAT' for column in X.columns[:10])\n",
    "sql_table_columns = ', '.join(column for column in table_creation)\n",
    "print(f'CREATE TABLE aps_data ({sql_table_columns});' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Classifiers on Data\n",
    "Two approach philosophies:\n",
    "* See which naive model has best performance over K folds, then tune that model to optimal performance.\n",
    "* Tune every model, to include the number of folds in the data, then evaluate those models over 10 folds.\n",
    "\n",
    "The models run pretty slowly on the data, so I'm going for the first approach where I'll use the vanilla settings to narrow down the field, then tune the model(s) that stand out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split stratified data into train/holdout, then split training data into stratified train/test folds\n",
    "\n",
    "The SKLearn method StratifiedShuffleSplit is used to split the data into a randomized training and holdout set that maintains the percentage of the positive class in the original data. From there, StratifiedKFolds is used to break the training set into cross-validation folds for assessing model performance.  \n",
    "\n",
    "The data set has a severe class imbalance, with the positive class (\"APS failure\") making up <2% of the set. Performing this split is necessary to ensure effective cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit:** Sklearn's `train_test_split()` method with the `stratify` parameter will accomplish the same as the method below. At the time I was focused on deliberately shuffling the dataset to make sure that some of the positive class eventually got into each CV fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and holdout sets\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.20, random_state=42)\n",
    "for train_index, holdout_index in sss.split(X_no_nan,y_no_nan):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", holdout_index)\n",
    "    X_train = X_no_nan.values[train_index]\n",
    "    X_test = X_no_nan.values[holdout_index]\n",
    "    y_train = y_no_nan.values[train_index]\n",
    "    y_test = y_no_nan.values[holdout_index]\n",
    "    \n",
    "    #Check that the train/test split does not overlap/include duplicates\n",
    "    assert(not set(train_index).intersection(set(holdout_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.007479915042940253, 0.007480260423881424)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate that splits are even\n",
    "np.sum(y_test==1)/len(y_test),  np.sum(y_train==1)/len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Performance of Classifiers\n",
    "The following blocks assess the performance of the vanilla models on the reduced data set using the ROC Area Under the Curve (AUC) assessment metric. A value closer to 1 is desirable.  \n",
    "\n",
    "Because of the heavy penalty on Type II errors in Scania's cost function, I've also gotten cross-validation scores for some of the models and data transformations using precision as well as ROC AUC.  \n",
    "\n",
    "Random Forest and Gradient Boosting classifiers stood out for their high AUC and relatively high precision in basic testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stratified folds for 10 fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4995303149252469"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SkLearn Dummy classifier \n",
    "np.mean(cross_val_score(DummyClassifier(),X_train,y_train,\n",
    "                        cv=skf, scoring = 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "162000\n"
     ]
    }
   ],
   "source": [
    "# Absolute baseline: Predicting everything as negative (no check needed)\n",
    "all_neg = np.zeros(len(y_train))\n",
    "print(roc_auc_score(y_train, all_neg))\n",
    "print(scania_score(y_train,all_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "429900\n"
     ]
    }
   ],
   "source": [
    "# Baseline: predicting everything as positive (needing a check)\n",
    "all_pos = np.zeros(len(y_train))+1\n",
    "print(roc_auc_score(y_train, all_pos))\n",
    "print(scania_score(y_train, all_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it looks like it's cheaper to Scania to not ever check the APS instead of always checking the APS. I think there are plenty of reasons why this still isn't a smart or ethical approach (driver safety among them), so hopefully we can do better using some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'knn': KNeighborsClassifier,\n",
    "    'lgr': LogisticRegression,\n",
    "    'gnb': GaussianNB,\n",
    "    #'mnb': MultinomialNB\n",
    "    'bnb': BernoulliNB,\n",
    "    'dtc': DecisionTreeClassifier,\n",
    "    'rfc': RandomForestClassifier,\n",
    "    'gbc': GradientBoostingClassifier,\n",
    "    'lsvc': LinearSVC,\n",
    "    # 'svc': SVC   ''' really, really slow'''\n",
    "}\n",
    "\n",
    "default_parameters = {\n",
    "    'knn': {},\n",
    "    'lgr': {'solver':'liblinear'},\n",
    "    'gnb': {},\n",
    "    #'mnb': {},\n",
    "    'bnb': {},\n",
    "    'dtc': {},\n",
    "    'rfc': {'n_estimators':100},\n",
    "    'gbc': {},\n",
    "    'lsvc': {},\n",
    "    # 'svc': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block from `model_abstraction.py` accepts a dictionary of model objects and returns the cross-validation scores for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'str'>, {'knn': 0.833807743344118, 'lgr': 0.9372424524378467, 'gnb': 0.9496054072652556, 'bnb': 0.9347346238025758, 'dtc': 0.8271712237518238, 'rfc': 0.9729079877631868, 'gbc': 0.9573550512980468, 'lsvc': 0.7038931710686771})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vanilla_unscaled_auc = cross_val_models(classifiers, X_train,y_train, use_cv=skf,\n",
    "                                        metric='roc_auc', params=default_parameters)\n",
    "print(vanilla_unscaled_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'str'>, {'knn': 0.28674242424242424, 'lgr': 0.5743371212121212, 'gnb': 0.8521780303030303, 'bnb': 0.7716856060606061, 'dtc': 0.6206439393939395, 'rfc': 0.5865530303030303, 'gbc': 0.6017992424242424, 'lsvc': 0.3502840909090909})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vanilla_unscaled_prcsn = cross_val_models(classifiers, X_train,y_train, use_cv=skf, metric='recall',\n",
    "                                         params=default_parameters)\n",
    "print(vanilla_unscaled_prcsn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Classifiers using Scaled Data\n",
    "\n",
    "Looking at the effects of scaled data on model performance. I would only expect changes from models operating in a linear space, such as KNeighbors, Logistic Regression, and SVC's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssx = StandardScaler()\n",
    "scaled_X_train = ssx.fit_transform(X_train)\n",
    "scaled_X_test = ssx.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'str'>, {'knn': 0.8639242433053493, 'lgr': 0.9203227759098311, 'gnb': 0.9457376230906412, 'bnb': 0.9093221556105366, 'dtc': 0.8181143804584577, 'rfc': 0.9323435528523193, 'gbc': 0.9571990402983076, 'lsvc': 0.8733829484658167})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vanilla_scaled = cross_val_models(classifiers, scaled_X_train,y_train, use_cv=skf, metric='roc_auc')\n",
    "print(vanilla_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'str'>, {'knn': 0.45681818181818185, 'lgr': 0.6053030303030302, 'gnb': 0.8704545454545455, 'bnb': 0.8609848484848485, 'dtc': 0.6207386363636364, 'rfc': 0.5095643939393939, 'gbc': 0.6081439393939394, 'lsvc': 0.5500946969696969})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vanilla_scaled_prcsn = cross_val_models(classifiers, scaled_X_train,y_train, use_cv=skf, metric='recall')\n",
    "print(vanilla_scaled_prcsn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Classifiers using PCA-reduced data\n",
    "\n",
    "Currently working with over 140 features. None of the principal components capture a majority representation of the variance, however I'm going to try putting the reduced components through classification models just to see how the AUC scores change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34499792, 0.06027573, 0.04941278, 0.02883688, 0.02672339,\n",
       "       0.02257314, 0.01788312, 0.01726799, 0.01596444, 0.01534512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(scaled_X_train)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scaled_X_train = pca.transform(scaled_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'str'>, {'knn': 0.8707792664079737, 'lgr': 0.9620230568067276, 'gnb': 0.9567179008331749, 'bnb': 0.8840788048841521, 'dtc': 0.7838390336547612, 'rfc': 0.958045971314682, 'gbc': 0.9637973308627092, 'lsvc': 0.9515936361169265})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vanilla_scaled_pca_auc = cross_val_models(classifiers, pca_scaled_X_train,y_train,\n",
    "                                      use_cv=skf, metric='roc_auc', params = default_parameters)\n",
    "print(vanilla_scaled_pca_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'str'>, {'knn': 0.43863636363636366, 'lgr': 0.44176136363636365, 'gnb': 0.7505681818181819, 'bnb': 0.0, 'dtc': 0.5679924242424242, 'rfc': 0.5429924242424242, 'gbc': 0.47547348484848484, 'lsvc': 0.37339015151515154})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vanilla_scaled_pca_prcsn = cross_val_models(classifiers, pca_scaled_X_train,y_train,\n",
    "                                      use_cv=skf, metric='recall', params = default_parameters)\n",
    "print(vanilla_scaled_pca_prcsn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model for MVP Reporting Purposes\n",
    "The following model was used to provide an update to my cohort in a short 30 second long presentation on where my project was going. **Note:** At this point I hadn't found Scania's actual test set on Kaggle (I was using the version from UCI's ML Repository)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MVP purposes, training vanilla GBM on X_train\n",
    "grb = GradientBoostingClassifier().fit(X_train,y_train)\n",
    "y_pred = grb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8266952909987273\n",
      "14100\n",
      "0.9233544416921791\n",
      "31110\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, y_pred))\n",
    "print(scania_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_no_nan, grb.predict(X_no_nan)))\n",
    "print(scania_score(y_no_nan, grb.predict(X_no_nan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2c00f048>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, ths = roc_curve(y_test, grb.predict_proba(X_test)[:,1])\n",
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10729,    19],\n",
       "       [   25,    56]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set results\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53715,    23],\n",
       "       [   64,   341]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for mvp\n",
    "confusion_matrix(y_no_nan, y_pred_whole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webapp model\n",
    "Code for a simple flask web app using a very reduced version of the data. Scale it down to one feature with PCA then train a model. Export the model and the scaler to a pickle file, then bring it into the cupcake_or_muffin folder in the in_progress directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = GradientBoostingClassifier().fit(pca_X_train,y_train)\n",
    "model_export = {'PCA_Reduction':pca,\n",
    "               'model': best_model}\n",
    "pickle.dump(model_export, open(\"scania_model_for_webapp.pkl\",\"wb\"))\n",
    "best_model.predict(np.array([.88]).reshape(-1,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning\n",
    "At this point I'm looking at 3 models, for different types of data:\n",
    "* Gradient Boosting on full data set, scaled\n",
    "* Random Forest and Gradient Boosting on PCA'ed data and regular data\n",
    "\n",
    "See [this guide](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/) for Gradient Boosting hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=False),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=False, n_iter=20, n_jobs=None,\n",
       "          param_distributions={'min_samples_split': [2, 10, 30, 100], 'max_depth': [3, 5, 10], 'max_features': ['auto', 'log2', None], 'n_estimators': [5, 10, 50, 100], 'subsample': [1, 0.9, 0.8, 0.7]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''    ********      MAKE THIS INTO A FUNCTION    ********        '''\n",
    "\n",
    "model = GradientBoostingClassifier\n",
    "const_params = {'random_state':42}\n",
    "tuning_params = {'min_samples_split':[2,10,30,100],\n",
    "                'max_depth':[3,5,10],\n",
    "                'max_features':['auto', 'log2', None],\n",
    "                'n_estimators':[5,10,50,100],\n",
    "                 'subsample':[1,0.9,0.8, 0.7],\n",
    "                }\n",
    "metric = 'roc_auc'\n",
    "use_cv = skf\n",
    "\n",
    "grid_gb_scaled = RandomizedSearchCV(model(**const_params), tuning_params, scoring = metric,\n",
    "                             iid=False, cv=use_cv, n_iter = 20)\n",
    "grid_gb_scaled.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score: 0.9705760390894289\n",
      "Test Score 0.7581892927538629\n"
     ]
    }
   ],
   "source": [
    "print('Best CV score:', grid_gb_scaled.best_score_)\n",
    "print('Test Score', roc_auc_score(y_test,grid_gb_scaled.predict(scaled_X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19730"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scania_score(y_test,grid_gb_scaled.predict(scaled_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1,\n",
       " 'n_estimators': 50,\n",
       " 'min_samples_split': 2,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 10}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_gb_scaled.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=False),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=False, n_iter=10, n_jobs=None,\n",
       "          param_distributions={'min_samples_split': [2, 10, 30, 100], 'max_depth': [3, 5, 10], 'max_features': ['auto', 'log2', None], 'n_estimators': [5, 10, 50, 100], 'subsample': [1, 0.9, 0.8, 0.7]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier\n",
    "const_params = {'random_state':42}\n",
    "tuning_params = {'min_samples_split':[2,10,30,100],\n",
    "                'max_depth':[3,5,10],\n",
    "                'max_features':['auto', 'log2', None],\n",
    "                'n_estimators':[5,10,50,100],\n",
    "                 'subsample':[1,0.9,0.8, 0.7],\n",
    "                }\n",
    "metric = 'roc_auc'\n",
    "use_cv = skf\n",
    "\n",
    "grid_gb_pca_scaled = RandomizedSearchCV(model(**const_params), tuning_params, scoring = metric,\n",
    "                             iid=False, cv=use_cv, n_iter = 10)\n",
    "grid_gb_pca_scaled.fit(pca_scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.9,\n",
       " 'n_estimators': 100,\n",
       " 'min_samples_split': 30,\n",
       " 'max_features': None,\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scania_score(y_test,grid_gb_pca_scaled.predict(pca.transform(scaled_X_test))))\n",
    "grid_gb_pca_scaled.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score: 0.9653572315972003\n",
      "Test Score 0.7643621322600358\n"
     ]
    }
   ],
   "source": [
    "print('Best CV score:', grid_gb_pca_scaled.best_score_)\n",
    "print('Test Score', roc_auc_score(y_test,grid_gb_pca_scaled.predict(pca.transform(scaled_X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing in Gradient Boosting algorithm from XGBoost library.\n",
    "The following blocks first test the general viability of an untrained XGBoost algorithm, then go into the appropriate cross-validation action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier( \n",
    "                       n_estimators=30000, #arbitrary large number b/c we're using early stopping\n",
    "                       max_depth=3,\n",
    "                       objective=\"binary:logistic\", \n",
    "                       subsample=1,\n",
    "                       min_child_weight=1,\n",
    "                       colsample_bytree=.8\n",
    "                      )\n",
    "\n",
    "eval_set=[(scaled_X_train,y_train),(scaled_X_test,y_test)] #tracking train/validation error as we go\n",
    "fit_model = gbm.fit( \n",
    "                    scaled_X_train, y_train, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='auc',\n",
    "                    early_stopping_rounds=50, # stop when validation error hasn't improved in this many rounds\n",
    "                    verbose=False #gives output log as below\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21010\n",
      "0.7406942204578973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10747,     1],\n",
       "       [   42,    39]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gauging model performance with default prediction threshold\n",
    "test = fit_model.predict(scaled_X_test, ntree_limit=gbm.best_ntree_limit)\n",
    "print(scania_score(y_test,test))\n",
    "print(roc_auc_score(y_test,test))\n",
    "confusion_matrix(y_test,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4460\n",
      "0.9677114777598588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10452,   296],\n",
       "       [    3,    78]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guaging model performance with lower threshold\n",
    "test = fit_model.predict_proba(scaled_X_test, ntree_limit=gbm.best_ntree_limit)[:,1] > 0.03\n",
    "print(scania_score(y_test,test))\n",
    "print(roc_auc_score(y_test,test))\n",
    "confusion_matrix(y_test,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually cross-validating model, then checking score on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9249411200279136\n"
     ]
    }
   ],
   "source": [
    "cross_val_score(gmb, aps_dm, scoring='auc')\n",
    "\n",
    "cv_scores = []\n",
    "for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "    \n",
    "    X_tr = X_train[train_idx]\n",
    "    y_tr = y_train[train_idx]\n",
    "    X_val = X_train[val_idx]\n",
    "    y_val = y_train[val_idx]\n",
    "   \n",
    "    gbm = xgb.XGBClassifier( \n",
    "                       n_estimators=30000, #arbitrary large number b/c we're using early stopping\n",
    "                       max_depth=3,\n",
    "                       objective=\"binary:logistic\",\n",
    "                       subsample=1,\n",
    "                       min_child_weight=1,\n",
    "                       colsample_bytree=.8\n",
    "                      )\n",
    "    eval_set=[(X_tr,y_tr),(X_val,y_val)] #tracking train/validation error as we go\n",
    "    fit_model = gbm.fit( \n",
    "                    X_tr, y_tr, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='auc',\n",
    "                    early_stopping_rounds=50, # stop when validation error hasn't improved in this many rounds\n",
    "                    verbose=False #gives output log as below\n",
    "                   )\n",
    "    \n",
    "    y_val_pred = fit_model.predict_proba(X_val, ntree_limit=gbm.best_ntree_limit)[:,1]\n",
    "    cv_scores.append(roc_auc_score(y_val,y_val_pred > 0.03))\n",
    "    \n",
    "    \n",
    "print(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9571479276075481\n",
      "4250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10623,   125],\n",
       "       [    6,    75]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating last fold's model\n",
    "cutoff = 0.03\n",
    "y_test_pred = fit_model.predict_proba(X_test)[:,1] > cutoff\n",
    "\n",
    "print(roc_auc_score(y_test,y_test_pred))\n",
    "print(scania_score(y_test,y_test_pred))\n",
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "Ensemble models like Gradient Boosting and Random Forest seem to work the best. Random Forest, specifically, seems to score high on AUC but also on precision, which should help avoid false negatives. I haven't yet figured out how to integrate Scania's error metric into the SKLearn environment, so I'll need to adapt something like the above block into my own cross validation function for future analysis. I've been using the ROC AUC metric as a stand-in, and while it does let me cut the wheat from the chaff, it doesn't align well enough with the Scania cost to make a final model decision.\n",
    "\n",
    "The scores above look good, although they are not done on the true test set for the competition (see `02_classification_testing.ipynb` for that).  \n",
    "\n",
    "There are two process improvements I'm looking to add that can take this model further:\n",
    "* The above tests were done on a data set where I didn't impute any missing rows, meaning I lost half my positive class (albeit still keeping just under 500 and stratifying). **Imputing the data and engineering features that acknowledge the 'na' values** (because even missing measurements mean something) will have an effect on model performance.\n",
    "* **Tuning the decision threshold.** I didn't realize this until I was running XGBoost and discovered that it prints out decimal values by default on its predict method. This had an extraordinary effect on lowering Scania's custom cost score, and I imagine changing that threshold will have similar effects for the Random Forest Classifier as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data      1.000000\n",
       "bj_000    0.492298\n",
       "am_0      0.478334\n",
       "aq_000    0.465263\n",
       "al_000    0.461792\n",
       "bb_000    0.449540\n",
       "bv_000    0.449540\n",
       "bu_000    0.449540\n",
       "cq_000    0.449540\n",
       "ap_000    0.440616\n",
       "bg_000    0.437689\n",
       "ah_000    0.437689\n",
       "ci_000    0.437532\n",
       "an_000    0.433719\n",
       "ao_000    0.425696\n",
       "dn_000    0.421138\n",
       "bh_000    0.420361\n",
       "bt_000    0.417634\n",
       "aa_000    0.417634\n",
       "ck_000    0.396130\n",
       "cc_000    0.391366\n",
       "bx_000    0.382500\n",
       "by_000    0.378954\n",
       "ee_005    0.370739\n",
       "cj_000    0.361503\n",
       "ds_000    0.359379\n",
       "dt_000    0.354983\n",
       "cs_004    0.351365\n",
       "ba_004    0.340400\n",
       "cn_004    0.335950\n",
       "            ...   \n",
       "ag_008    0.072418\n",
       "az_006    0.069360\n",
       "ai_000    0.065010\n",
       "cp_000    0.063463\n",
       "ag_009    0.058421\n",
       "az_008    0.053314\n",
       "ca_000    0.052061\n",
       "ay_009    0.049906\n",
       "dh_000    0.047875\n",
       "cb_000    0.047305\n",
       "dk_000    0.023207\n",
       "eg_000    0.020316\n",
       "cs_007    0.015957\n",
       "aj_000    0.015029\n",
       "af_000    0.014378\n",
       "ak_000    0.010191\n",
       "dm_000    0.007623\n",
       "ef_000    0.006269\n",
       "ea_000    0.005837\n",
       "az_009    0.002972\n",
       "ag_000    0.001886\n",
       "ae_000    0.001334\n",
       "cs_008    0.000018\n",
       "dz_000   -0.000281\n",
       "cs_009   -0.000386\n",
       "as_000   -0.000702\n",
       "dj_000   -0.000896\n",
       "dl_000   -0.002182\n",
       "ac_000   -0.031244\n",
       "cd_000         NaN\n",
       "Name: data, Length: 143, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_nan['data'] = y_no_nan\n",
    "correlations = X_no_nan.corr()\n",
    "correlations['data'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209600.0    54143\n",
       "Name: cd_000, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_nan['cd_000'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209600    59324\n",
       "na           676\n",
       "Name: cd_000, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aps['cd_000'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
